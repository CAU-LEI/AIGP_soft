
#!/usr/bin/env python
# main.py
"""
AIGP Main Program Entry
Usage examples:
  Train regression model:
    python main.py --geno data/test_x.txt --geno_sep "\t" --phe data/test_y.txt --phe_sep "\s" --phe_col_num 1 --type regression --model LinearRegression --train_size 0.8
  Train classification model with PCA dimensionality reduction and grid search:
    python main.py --geno data/test_x.txt --geno_sep "\t" --phe data/test_y.txt --phe_sep "\s" --phe_col_num 1 --type classification --model LogisticRegression --dim_reduction pca --n_components 20 --grid --grid_model_params "{\"fit_intercept\": [true, false], \"C\": [1.0, 100]}" --n_jobs 4
  (Note: JSON parameters must conform to standard format)
"""


import matplotlib
matplotlib.use('Agg')
from aigp.cli import parse_args
from aigp.data_loader import load_training_data, calculate_geno_stats, calculate_phe_stats
from aigp.dim_reduction import reduce_dimensions
from aigp.model_factory import get_model
from aigp.trainer import train_model, save_feature_importance
from aigp.shap_analysis import analyze_shap


def main():
    args = parse_args()

    # è¯»å–è®­ç»ƒæ•°æ®ï¼ŒåŒæ—¶è¿›è¡Œè¡¨å‹åˆ—è‡ªåŠ¨æ£€æµ‹å’Œæ•°æ®æ¸…æ´—ï¼ˆæ ¹æ®ä»»åŠ¡ç±»å‹ï¼‰
    X, y, covariates = load_training_data(args.geno, args.geno_sep, args.phe, args.phe_sep,
                                          args.phe_col_num, args.category_cols, task_type=args.type)
    
    # è‡ªåŠ¨åŒ–é¢„æµ‹æ¨¡å¼
    if args.auto:
        from aigp.auto_predictor import auto_predict
        print("ğŸ¤– å¯ç”¨è‡ªåŠ¨åŒ–é¢„æµ‹æ¨¡å¼...")
        predictor = auto_predict(
            args.geno, args.phe, args.type, args.cv, args.n_jobs,
            args.phe_col_num, args.category_cols, 
            args.auto_optimize, args.auto_preprocess
        )
        
        # å¦‚æœæŒ‡å®šäº†SHAPåˆ†æï¼Œå¯¹æœ€ä½³æ¨¡å‹è¿›è¡ŒSHAPåˆ†æ
        if args.shap:
            print("\nğŸ” å¯¹æœ€ä½³æ¨¡å‹è¿›è¡ŒSHAPåˆ†æ...")
            best_model = predictor.get_best_model()
            if best_model is not None:
                from aigp.shap_analysis import run_shap_analysis
                run_shap_analysis(
                    best_model, X, y, args.type, 
                    args.shap_beeswarm, args.shap_feature_heatmap, 
                    args.shap_feature_waterfall, args.top_features, 
                    args.output_dir
                )
        
        return

    # è®¡ç®—åŸºå› å‹æ•°æ®ç»Ÿè®¡ä¿¡æ¯ï¼ˆè‹¥æŒ‡å®šï¼‰
    if args.geno_cal:
        geno_stats = calculate_geno_stats(X)
        geno_stats.to_csv("geno_stats.csv", index=False)
        print("åŸºå› å‹ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ° geno_stats.csv")

    # è®¡ç®—è¡¨å‹ç»Ÿè®¡ä¿¡æ¯ï¼ˆè‹¥æŒ‡å®šï¼‰
    if args.phe_cal and y is not None:
        calculate_phe_stats(y)

    # é™ç»´ï¼šè‹¥æŒ‡å®šäº†é™ç»´æ–¹æ³•å’Œç›®æ ‡ç»´åº¦
    if args.dim_reduction and args.n_components:
        print("è¿›è¡Œ {} é™ç»´ï¼Œç›®æ ‡ç»´åº¦ï¼š{}".format(args.dim_reduction, args.n_components))
        X_reduced = reduce_dimensions(X, args.dim_reduction, args.n_components)
        import pandas as pd
        X_reduced = pd.DataFrame(X_reduced, columns=["PC{}".format(i + 1) for i in range(args.n_components)])
        if covariates is not None:
            X = pd.concat([X_reduced, covariates.reset_index(drop=True)], axis=1)
        else:
            X = X_reduced
    else:
        if covariates is not None:
            import pandas as pd
            X = pd.concat([X.reset_index(drop=True), covariates.reset_index(drop=True)], axis=1)

    # æ„é€ æ¨¡å‹
    model = get_model(task_type="regression" if args.type == "regression" else "classification",
                      model_name=args.model,
                      model_params=args.model_params,
                      gpu=args.gpu,
                      categorical=(args.category_cols is not None))

    # æ¨¡å‹è®­ç»ƒï¼šæ”¯æŒäº¤å‰éªŒè¯ã€ç½‘æ ¼æœç´¢ã€SSA æœç´¢ï¼Œä¼ å…¥ n_jobs å‚æ•°å®ç°å¹¶è¡Œè®¡ç®—
    model, score, extra_info = train_model(model, X, y,
                                           task_type="regression" if args.type == "regression" else "classification",
                                           cv=args.cv, train_size=args.train_size, ntest=args.ntest,
                                           grid=args.grid, grid_params=args.grid_model_params,
                                           ssa=args.ssa, ssa_params=args.ssa_model_params,
                                           n_jobs=args.n_jobs,save_checkpoint=args.save_checkpoint,
                                           result_file=args.result_file)

    # SHAP åˆ†æ
    if args.shap:
        print("å¼€å§‹ SHAP åˆ†æ...")
        feature_names = X.columns if hasattr(X, "columns") else None
        analyze_shap(model, X, feature_names=feature_names, output=args.output_dir,
                     shap_beeswarm=args.shap_beeswarm,
                     shap_feature_heatmap=args.shap_feature_heatmap,
                     shap_feature_waterfall=args.shap_feature_waterfall,
                     top_features=args.top_features)

    # ç‰¹å¾é‡è¦æ€§è¾“å‡º
    if args.importance:
        save_feature_importance(model, X)


if __name__ == "__main__":
    args = parse_args()
    print("save_checkpoint:", args.save_checkpoint)
    main()


"""
python main1.py --geno data/test_x.txt --geno_sep "\t" --phe data/test_y.txt --phe_sep "\s" --phe_col_num 1 --type sort --model LogisticRegression --dim_reduction pca --n_components 20 --grid --grid_model_params "{\"fit_intercept\": [true, false], \"C\": [1.0, 100]}" --geno_cal --phe_cal --n_jobs 4 --train_size 0.8


"""